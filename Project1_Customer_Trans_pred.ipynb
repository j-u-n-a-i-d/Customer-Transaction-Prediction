{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32fd5090",
   "metadata": {},
   "source": [
    "# Customer Transaction Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "372884d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31981754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>train_199995</td>\n",
       "      <td>0</td>\n",
       "      <td>11.4880</td>\n",
       "      <td>-0.4956</td>\n",
       "      <td>8.2622</td>\n",
       "      <td>3.5142</td>\n",
       "      <td>10.3404</td>\n",
       "      <td>11.6081</td>\n",
       "      <td>5.6709</td>\n",
       "      <td>15.1516</td>\n",
       "      <td>...</td>\n",
       "      <td>6.1415</td>\n",
       "      <td>13.2305</td>\n",
       "      <td>3.9901</td>\n",
       "      <td>0.9388</td>\n",
       "      <td>18.0249</td>\n",
       "      <td>-1.7939</td>\n",
       "      <td>2.1661</td>\n",
       "      <td>8.5326</td>\n",
       "      <td>16.6660</td>\n",
       "      <td>-17.8661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>train_199996</td>\n",
       "      <td>0</td>\n",
       "      <td>4.9149</td>\n",
       "      <td>-2.4484</td>\n",
       "      <td>16.7052</td>\n",
       "      <td>6.6345</td>\n",
       "      <td>8.3096</td>\n",
       "      <td>-10.5628</td>\n",
       "      <td>5.8802</td>\n",
       "      <td>21.5940</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9611</td>\n",
       "      <td>4.6549</td>\n",
       "      <td>0.6998</td>\n",
       "      <td>1.8341</td>\n",
       "      <td>22.2717</td>\n",
       "      <td>1.7337</td>\n",
       "      <td>-2.1651</td>\n",
       "      <td>6.7419</td>\n",
       "      <td>15.9054</td>\n",
       "      <td>0.3388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>train_199997</td>\n",
       "      <td>0</td>\n",
       "      <td>11.2232</td>\n",
       "      <td>-5.0518</td>\n",
       "      <td>10.5127</td>\n",
       "      <td>5.6456</td>\n",
       "      <td>9.3410</td>\n",
       "      <td>-5.4086</td>\n",
       "      <td>4.5555</td>\n",
       "      <td>21.5571</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0651</td>\n",
       "      <td>5.4414</td>\n",
       "      <td>3.1032</td>\n",
       "      <td>4.8793</td>\n",
       "      <td>23.5311</td>\n",
       "      <td>-1.5736</td>\n",
       "      <td>1.2832</td>\n",
       "      <td>8.7155</td>\n",
       "      <td>13.8329</td>\n",
       "      <td>4.1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>train_199998</td>\n",
       "      <td>0</td>\n",
       "      <td>9.7148</td>\n",
       "      <td>-8.6098</td>\n",
       "      <td>13.6104</td>\n",
       "      <td>5.7930</td>\n",
       "      <td>12.5173</td>\n",
       "      <td>0.5339</td>\n",
       "      <td>6.0479</td>\n",
       "      <td>17.0152</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6840</td>\n",
       "      <td>8.6587</td>\n",
       "      <td>2.7337</td>\n",
       "      <td>11.1178</td>\n",
       "      <td>20.4158</td>\n",
       "      <td>-0.0786</td>\n",
       "      <td>6.7980</td>\n",
       "      <td>10.0342</td>\n",
       "      <td>15.5289</td>\n",
       "      <td>-13.9001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>train_199999</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8762</td>\n",
       "      <td>-5.7105</td>\n",
       "      <td>12.1183</td>\n",
       "      <td>8.0328</td>\n",
       "      <td>11.5577</td>\n",
       "      <td>0.3488</td>\n",
       "      <td>5.2839</td>\n",
       "      <td>15.2058</td>\n",
       "      <td>...</td>\n",
       "      <td>8.9842</td>\n",
       "      <td>1.6893</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.3766</td>\n",
       "      <td>15.2101</td>\n",
       "      <td>-2.4907</td>\n",
       "      <td>-2.2342</td>\n",
       "      <td>8.1857</td>\n",
       "      <td>12.1284</td>\n",
       "      <td>0.1385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID_code  target    var_0   var_1    var_2   var_3    var_4  \\\n",
       "0            train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607   \n",
       "1            train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622   \n",
       "2            train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825   \n",
       "3            train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846   \n",
       "4            train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772   \n",
       "...              ...     ...      ...     ...      ...     ...      ...   \n",
       "199995  train_199995       0  11.4880 -0.4956   8.2622  3.5142  10.3404   \n",
       "199996  train_199996       0   4.9149 -2.4484  16.7052  6.6345   8.3096   \n",
       "199997  train_199997       0  11.2232 -5.0518  10.5127  5.6456   9.3410   \n",
       "199998  train_199998       0   9.7148 -8.6098  13.6104  5.7930  12.5173   \n",
       "199999  train_199999       0  10.8762 -5.7105  12.1183  8.0328  11.5577   \n",
       "\n",
       "          var_5   var_6    var_7  ...  var_190  var_191  var_192  var_193  \\\n",
       "0       -9.2834  5.1187  18.6266  ...   4.4354   3.9642   3.1364   1.6910   \n",
       "1        7.0433  5.6208  16.5338  ...   7.6421   7.7214   2.5837  10.9516   \n",
       "2       -9.0837  6.9427  14.6155  ...   2.9057   9.7905   1.6704   1.6858   \n",
       "3       -1.8361  5.8428  14.9250  ...   4.4666   4.7433   0.7178   1.4214   \n",
       "4        2.4486  5.9405  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942   \n",
       "...         ...     ...      ...  ...      ...      ...      ...      ...   \n",
       "199995  11.6081  5.6709  15.1516  ...   6.1415  13.2305   3.9901   0.9388   \n",
       "199996 -10.5628  5.8802  21.5940  ...   4.9611   4.6549   0.6998   1.8341   \n",
       "199997  -5.4086  4.5555  21.5571  ...   4.0651   5.4414   3.1032   4.8793   \n",
       "199998   0.5339  6.0479  17.0152  ...   2.6840   8.6587   2.7337  11.1178   \n",
       "199999   0.3488  5.2839  15.2058  ...   8.9842   1.6893   0.1276   0.3766   \n",
       "\n",
       "        var_194  var_195  var_196  var_197  var_198  var_199  \n",
       "0       18.5227  -2.3978   7.8784   8.5635  12.7803  -1.0914  \n",
       "1       15.4305   2.0339   8.1267   8.7889  18.3560   1.9518  \n",
       "2       21.6042   3.1417  -6.5213   8.2675  14.7222   0.3965  \n",
       "3       23.0347  -1.2706  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4       13.2876  -1.5121   3.9267   9.5031  17.9974  -8.8104  \n",
       "...         ...      ...      ...      ...      ...      ...  \n",
       "199995  18.0249  -1.7939   2.1661   8.5326  16.6660 -17.8661  \n",
       "199996  22.2717   1.7337  -2.1651   6.7419  15.9054   0.3388  \n",
       "199997  23.5311  -1.5736   1.2832   8.7155  13.8329   4.1995  \n",
       "199998  20.4158  -0.0786   6.7980  10.0342  15.5289 -13.9001  \n",
       "199999  15.2101  -2.4907  -2.2342   8.1857  12.1284   0.1385  \n",
       "\n",
       "[200000 rows x 202 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train(1).csv')   # Loading the dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7279ba",
   "metadata": {},
   "source": [
    "# Business Statement"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2b9bad7a",
   "metadata": {},
   "source": [
    "By using the given features we have to predict whether the customer makes a transaction in the future or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ee14ad",
   "metadata": {},
   "source": [
    "# Basic checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd006f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()            # First 5 rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c64ba715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>train_199995</td>\n",
       "      <td>0</td>\n",
       "      <td>11.4880</td>\n",
       "      <td>-0.4956</td>\n",
       "      <td>8.2622</td>\n",
       "      <td>3.5142</td>\n",
       "      <td>10.3404</td>\n",
       "      <td>11.6081</td>\n",
       "      <td>5.6709</td>\n",
       "      <td>15.1516</td>\n",
       "      <td>...</td>\n",
       "      <td>6.1415</td>\n",
       "      <td>13.2305</td>\n",
       "      <td>3.9901</td>\n",
       "      <td>0.9388</td>\n",
       "      <td>18.0249</td>\n",
       "      <td>-1.7939</td>\n",
       "      <td>2.1661</td>\n",
       "      <td>8.5326</td>\n",
       "      <td>16.6660</td>\n",
       "      <td>-17.8661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>train_199996</td>\n",
       "      <td>0</td>\n",
       "      <td>4.9149</td>\n",
       "      <td>-2.4484</td>\n",
       "      <td>16.7052</td>\n",
       "      <td>6.6345</td>\n",
       "      <td>8.3096</td>\n",
       "      <td>-10.5628</td>\n",
       "      <td>5.8802</td>\n",
       "      <td>21.5940</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9611</td>\n",
       "      <td>4.6549</td>\n",
       "      <td>0.6998</td>\n",
       "      <td>1.8341</td>\n",
       "      <td>22.2717</td>\n",
       "      <td>1.7337</td>\n",
       "      <td>-2.1651</td>\n",
       "      <td>6.7419</td>\n",
       "      <td>15.9054</td>\n",
       "      <td>0.3388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>train_199997</td>\n",
       "      <td>0</td>\n",
       "      <td>11.2232</td>\n",
       "      <td>-5.0518</td>\n",
       "      <td>10.5127</td>\n",
       "      <td>5.6456</td>\n",
       "      <td>9.3410</td>\n",
       "      <td>-5.4086</td>\n",
       "      <td>4.5555</td>\n",
       "      <td>21.5571</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0651</td>\n",
       "      <td>5.4414</td>\n",
       "      <td>3.1032</td>\n",
       "      <td>4.8793</td>\n",
       "      <td>23.5311</td>\n",
       "      <td>-1.5736</td>\n",
       "      <td>1.2832</td>\n",
       "      <td>8.7155</td>\n",
       "      <td>13.8329</td>\n",
       "      <td>4.1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>train_199998</td>\n",
       "      <td>0</td>\n",
       "      <td>9.7148</td>\n",
       "      <td>-8.6098</td>\n",
       "      <td>13.6104</td>\n",
       "      <td>5.7930</td>\n",
       "      <td>12.5173</td>\n",
       "      <td>0.5339</td>\n",
       "      <td>6.0479</td>\n",
       "      <td>17.0152</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6840</td>\n",
       "      <td>8.6587</td>\n",
       "      <td>2.7337</td>\n",
       "      <td>11.1178</td>\n",
       "      <td>20.4158</td>\n",
       "      <td>-0.0786</td>\n",
       "      <td>6.7980</td>\n",
       "      <td>10.0342</td>\n",
       "      <td>15.5289</td>\n",
       "      <td>-13.9001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>train_199999</td>\n",
       "      <td>0</td>\n",
       "      <td>10.8762</td>\n",
       "      <td>-5.7105</td>\n",
       "      <td>12.1183</td>\n",
       "      <td>8.0328</td>\n",
       "      <td>11.5577</td>\n",
       "      <td>0.3488</td>\n",
       "      <td>5.2839</td>\n",
       "      <td>15.2058</td>\n",
       "      <td>...</td>\n",
       "      <td>8.9842</td>\n",
       "      <td>1.6893</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.3766</td>\n",
       "      <td>15.2101</td>\n",
       "      <td>-2.4907</td>\n",
       "      <td>-2.2342</td>\n",
       "      <td>8.1857</td>\n",
       "      <td>12.1284</td>\n",
       "      <td>0.1385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID_code  target    var_0   var_1    var_2   var_3    var_4  \\\n",
       "199995  train_199995       0  11.4880 -0.4956   8.2622  3.5142  10.3404   \n",
       "199996  train_199996       0   4.9149 -2.4484  16.7052  6.6345   8.3096   \n",
       "199997  train_199997       0  11.2232 -5.0518  10.5127  5.6456   9.3410   \n",
       "199998  train_199998       0   9.7148 -8.6098  13.6104  5.7930  12.5173   \n",
       "199999  train_199999       0  10.8762 -5.7105  12.1183  8.0328  11.5577   \n",
       "\n",
       "          var_5   var_6    var_7  ...  var_190  var_191  var_192  var_193  \\\n",
       "199995  11.6081  5.6709  15.1516  ...   6.1415  13.2305   3.9901   0.9388   \n",
       "199996 -10.5628  5.8802  21.5940  ...   4.9611   4.6549   0.6998   1.8341   \n",
       "199997  -5.4086  4.5555  21.5571  ...   4.0651   5.4414   3.1032   4.8793   \n",
       "199998   0.5339  6.0479  17.0152  ...   2.6840   8.6587   2.7337  11.1178   \n",
       "199999   0.3488  5.2839  15.2058  ...   8.9842   1.6893   0.1276   0.3766   \n",
       "\n",
       "        var_194  var_195  var_196  var_197  var_198  var_199  \n",
       "199995  18.0249  -1.7939   2.1661   8.5326  16.6660 -17.8661  \n",
       "199996  22.2717   1.7337  -2.1651   6.7419  15.9054   0.3388  \n",
       "199997  23.5311  -1.5736   1.2832   8.7155  13.8329   4.1995  \n",
       "199998  20.4158  -0.0786   6.7980  10.0342  15.5289 -13.9001  \n",
       "199999  15.2101  -2.4907  -2.2342   8.1857  12.1284   0.1385  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()               # Last 5 rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "940d4ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.100490</td>\n",
       "      <td>10.679914</td>\n",
       "      <td>-1.627622</td>\n",
       "      <td>10.715192</td>\n",
       "      <td>6.796529</td>\n",
       "      <td>11.078333</td>\n",
       "      <td>-5.065317</td>\n",
       "      <td>5.408949</td>\n",
       "      <td>16.545850</td>\n",
       "      <td>0.284162</td>\n",
       "      <td>...</td>\n",
       "      <td>3.234440</td>\n",
       "      <td>7.438408</td>\n",
       "      <td>1.927839</td>\n",
       "      <td>3.331774</td>\n",
       "      <td>17.993784</td>\n",
       "      <td>-0.142088</td>\n",
       "      <td>2.303335</td>\n",
       "      <td>8.908158</td>\n",
       "      <td>15.870720</td>\n",
       "      <td>-3.326537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.300653</td>\n",
       "      <td>3.040051</td>\n",
       "      <td>4.050044</td>\n",
       "      <td>2.640894</td>\n",
       "      <td>2.043319</td>\n",
       "      <td>1.623150</td>\n",
       "      <td>7.863267</td>\n",
       "      <td>0.866607</td>\n",
       "      <td>3.418076</td>\n",
       "      <td>3.332634</td>\n",
       "      <td>...</td>\n",
       "      <td>4.559922</td>\n",
       "      <td>3.023272</td>\n",
       "      <td>1.478423</td>\n",
       "      <td>3.992030</td>\n",
       "      <td>3.135162</td>\n",
       "      <td>1.429372</td>\n",
       "      <td>5.454369</td>\n",
       "      <td>0.921625</td>\n",
       "      <td>3.010945</td>\n",
       "      <td>10.438015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408400</td>\n",
       "      <td>-15.043400</td>\n",
       "      <td>2.117100</td>\n",
       "      <td>-0.040200</td>\n",
       "      <td>5.074800</td>\n",
       "      <td>-32.562600</td>\n",
       "      <td>2.347300</td>\n",
       "      <td>5.349700</td>\n",
       "      <td>-10.505500</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.093300</td>\n",
       "      <td>-2.691700</td>\n",
       "      <td>-3.814500</td>\n",
       "      <td>-11.783400</td>\n",
       "      <td>8.694400</td>\n",
       "      <td>-5.261000</td>\n",
       "      <td>-14.209600</td>\n",
       "      <td>5.960600</td>\n",
       "      <td>6.299300</td>\n",
       "      <td>-38.852800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.453850</td>\n",
       "      <td>-4.740025</td>\n",
       "      <td>8.722475</td>\n",
       "      <td>5.254075</td>\n",
       "      <td>9.883175</td>\n",
       "      <td>-11.200350</td>\n",
       "      <td>4.767700</td>\n",
       "      <td>13.943800</td>\n",
       "      <td>-2.317800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058825</td>\n",
       "      <td>5.157400</td>\n",
       "      <td>0.889775</td>\n",
       "      <td>0.584600</td>\n",
       "      <td>15.629800</td>\n",
       "      <td>-1.170700</td>\n",
       "      <td>-1.946925</td>\n",
       "      <td>8.252800</td>\n",
       "      <td>13.829700</td>\n",
       "      <td>-11.208475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.524750</td>\n",
       "      <td>-1.608050</td>\n",
       "      <td>10.580000</td>\n",
       "      <td>6.825000</td>\n",
       "      <td>11.108250</td>\n",
       "      <td>-4.833150</td>\n",
       "      <td>5.385100</td>\n",
       "      <td>16.456800</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>...</td>\n",
       "      <td>3.203600</td>\n",
       "      <td>7.347750</td>\n",
       "      <td>1.901300</td>\n",
       "      <td>3.396350</td>\n",
       "      <td>17.957950</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>2.408900</td>\n",
       "      <td>8.888200</td>\n",
       "      <td>15.934050</td>\n",
       "      <td>-2.819550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.758200</td>\n",
       "      <td>1.358625</td>\n",
       "      <td>12.516700</td>\n",
       "      <td>8.324100</td>\n",
       "      <td>12.261125</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.102900</td>\n",
       "      <td>2.937900</td>\n",
       "      <td>...</td>\n",
       "      <td>6.406200</td>\n",
       "      <td>9.512525</td>\n",
       "      <td>2.949500</td>\n",
       "      <td>6.205800</td>\n",
       "      <td>20.396525</td>\n",
       "      <td>0.829600</td>\n",
       "      <td>6.556725</td>\n",
       "      <td>9.593300</td>\n",
       "      <td>18.064725</td>\n",
       "      <td>4.836800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.315000</td>\n",
       "      <td>10.376800</td>\n",
       "      <td>19.353000</td>\n",
       "      <td>13.188300</td>\n",
       "      <td>16.671400</td>\n",
       "      <td>17.251600</td>\n",
       "      <td>8.447700</td>\n",
       "      <td>27.691800</td>\n",
       "      <td>10.151300</td>\n",
       "      <td>...</td>\n",
       "      <td>18.440900</td>\n",
       "      <td>16.716500</td>\n",
       "      <td>8.402400</td>\n",
       "      <td>18.281800</td>\n",
       "      <td>27.928800</td>\n",
       "      <td>4.272900</td>\n",
       "      <td>18.321500</td>\n",
       "      <td>12.000400</td>\n",
       "      <td>26.079100</td>\n",
       "      <td>28.500700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              target          var_0          var_1          var_2  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.100490      10.679914      -1.627622      10.715192   \n",
       "std         0.300653       3.040051       4.050044       2.640894   \n",
       "min         0.000000       0.408400     -15.043400       2.117100   \n",
       "25%         0.000000       8.453850      -4.740025       8.722475   \n",
       "50%         0.000000      10.524750      -1.608050      10.580000   \n",
       "75%         0.000000      12.758200       1.358625      12.516700   \n",
       "max         1.000000      20.315000      10.376800      19.353000   \n",
       "\n",
       "               var_3          var_4          var_5          var_6  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        6.796529      11.078333      -5.065317       5.408949   \n",
       "std         2.043319       1.623150       7.863267       0.866607   \n",
       "min        -0.040200       5.074800     -32.562600       2.347300   \n",
       "25%         5.254075       9.883175     -11.200350       4.767700   \n",
       "50%         6.825000      11.108250      -4.833150       5.385100   \n",
       "75%         8.324100      12.261125       0.924800       6.003000   \n",
       "max        13.188300      16.671400      17.251600       8.447700   \n",
       "\n",
       "               var_7          var_8  ...        var_190        var_191  \\\n",
       "count  200000.000000  200000.000000  ...  200000.000000  200000.000000   \n",
       "mean       16.545850       0.284162  ...       3.234440       7.438408   \n",
       "std         3.418076       3.332634  ...       4.559922       3.023272   \n",
       "min         5.349700     -10.505500  ...     -14.093300      -2.691700   \n",
       "25%        13.943800      -2.317800  ...      -0.058825       5.157400   \n",
       "50%        16.456800       0.393700  ...       3.203600       7.347750   \n",
       "75%        19.102900       2.937900  ...       6.406200       9.512525   \n",
       "max        27.691800      10.151300  ...      18.440900      16.716500   \n",
       "\n",
       "             var_192        var_193        var_194        var_195  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        1.927839       3.331774      17.993784      -0.142088   \n",
       "std         1.478423       3.992030       3.135162       1.429372   \n",
       "min        -3.814500     -11.783400       8.694400      -5.261000   \n",
       "25%         0.889775       0.584600      15.629800      -1.170700   \n",
       "50%         1.901300       3.396350      17.957950      -0.172700   \n",
       "75%         2.949500       6.205800      20.396525       0.829600   \n",
       "max         8.402400      18.281800      27.928800       4.272900   \n",
       "\n",
       "             var_196        var_197        var_198        var_199  \n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000  \n",
       "mean        2.303335       8.908158      15.870720      -3.326537  \n",
       "std         5.454369       0.921625       3.010945      10.438015  \n",
       "min       -14.209600       5.960600       6.299300     -38.852800  \n",
       "25%        -1.946925       8.252800      13.829700     -11.208475  \n",
       "50%         2.408900       8.888200      15.934050      -2.819550  \n",
       "75%         6.556725       9.593300      18.064725       4.836800  \n",
       "max        18.321500      12.000400      26.079100      28.500700  \n",
       "\n",
       "[8 rows x 201 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()               # Statistical information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c334e1b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Columns: 202 entries, ID_code to var_199\n",
      "dtypes: float64(200), int64(1), object(1)\n",
      "memory usage: 308.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()               # Information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07555d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'ID_code' column indicates id numbers and it independent of target column \n",
    "df1 = df.drop('ID_code', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b2a7908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>0</td>\n",
       "      <td>11.4880</td>\n",
       "      <td>-0.4956</td>\n",
       "      <td>8.2622</td>\n",
       "      <td>3.5142</td>\n",
       "      <td>10.3404</td>\n",
       "      <td>11.6081</td>\n",
       "      <td>5.6709</td>\n",
       "      <td>15.1516</td>\n",
       "      <td>-0.6209</td>\n",
       "      <td>...</td>\n",
       "      <td>6.1415</td>\n",
       "      <td>13.2305</td>\n",
       "      <td>3.9901</td>\n",
       "      <td>0.9388</td>\n",
       "      <td>18.0249</td>\n",
       "      <td>-1.7939</td>\n",
       "      <td>2.1661</td>\n",
       "      <td>8.5326</td>\n",
       "      <td>16.6660</td>\n",
       "      <td>-17.8661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>0</td>\n",
       "      <td>4.9149</td>\n",
       "      <td>-2.4484</td>\n",
       "      <td>16.7052</td>\n",
       "      <td>6.6345</td>\n",
       "      <td>8.3096</td>\n",
       "      <td>-10.5628</td>\n",
       "      <td>5.8802</td>\n",
       "      <td>21.5940</td>\n",
       "      <td>-3.6797</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9611</td>\n",
       "      <td>4.6549</td>\n",
       "      <td>0.6998</td>\n",
       "      <td>1.8341</td>\n",
       "      <td>22.2717</td>\n",
       "      <td>1.7337</td>\n",
       "      <td>-2.1651</td>\n",
       "      <td>6.7419</td>\n",
       "      <td>15.9054</td>\n",
       "      <td>0.3388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>0</td>\n",
       "      <td>11.2232</td>\n",
       "      <td>-5.0518</td>\n",
       "      <td>10.5127</td>\n",
       "      <td>5.6456</td>\n",
       "      <td>9.3410</td>\n",
       "      <td>-5.4086</td>\n",
       "      <td>4.5555</td>\n",
       "      <td>21.5571</td>\n",
       "      <td>0.1202</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0651</td>\n",
       "      <td>5.4414</td>\n",
       "      <td>3.1032</td>\n",
       "      <td>4.8793</td>\n",
       "      <td>23.5311</td>\n",
       "      <td>-1.5736</td>\n",
       "      <td>1.2832</td>\n",
       "      <td>8.7155</td>\n",
       "      <td>13.8329</td>\n",
       "      <td>4.1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>0</td>\n",
       "      <td>9.7148</td>\n",
       "      <td>-8.6098</td>\n",
       "      <td>13.6104</td>\n",
       "      <td>5.7930</td>\n",
       "      <td>12.5173</td>\n",
       "      <td>0.5339</td>\n",
       "      <td>6.0479</td>\n",
       "      <td>17.0152</td>\n",
       "      <td>-2.1926</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6840</td>\n",
       "      <td>8.6587</td>\n",
       "      <td>2.7337</td>\n",
       "      <td>11.1178</td>\n",
       "      <td>20.4158</td>\n",
       "      <td>-0.0786</td>\n",
       "      <td>6.7980</td>\n",
       "      <td>10.0342</td>\n",
       "      <td>15.5289</td>\n",
       "      <td>-13.9001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>0</td>\n",
       "      <td>10.8762</td>\n",
       "      <td>-5.7105</td>\n",
       "      <td>12.1183</td>\n",
       "      <td>8.0328</td>\n",
       "      <td>11.5577</td>\n",
       "      <td>0.3488</td>\n",
       "      <td>5.2839</td>\n",
       "      <td>15.2058</td>\n",
       "      <td>-0.4541</td>\n",
       "      <td>...</td>\n",
       "      <td>8.9842</td>\n",
       "      <td>1.6893</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.3766</td>\n",
       "      <td>15.2101</td>\n",
       "      <td>-2.4907</td>\n",
       "      <td>-2.2342</td>\n",
       "      <td>8.1857</td>\n",
       "      <td>12.1284</td>\n",
       "      <td>0.1385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        target    var_0   var_1    var_2   var_3    var_4    var_5   var_6  \\\n",
       "0            0   8.9255 -6.7863  11.9081  5.0930  11.4607  -9.2834  5.1187   \n",
       "1            0  11.5006 -4.1473  13.8588  5.3890  12.3622   7.0433  5.6208   \n",
       "2            0   8.6093 -2.7457  12.0805  7.8928  10.5825  -9.0837  6.9427   \n",
       "3            0  11.0604 -2.1518   8.9522  7.1957  12.5846  -1.8361  5.8428   \n",
       "4            0   9.8369 -1.4834  12.8746  6.6375  12.2772   2.4486  5.9405   \n",
       "...        ...      ...     ...      ...     ...      ...      ...     ...   \n",
       "199995       0  11.4880 -0.4956   8.2622  3.5142  10.3404  11.6081  5.6709   \n",
       "199996       0   4.9149 -2.4484  16.7052  6.6345   8.3096 -10.5628  5.8802   \n",
       "199997       0  11.2232 -5.0518  10.5127  5.6456   9.3410  -5.4086  4.5555   \n",
       "199998       0   9.7148 -8.6098  13.6104  5.7930  12.5173   0.5339  6.0479   \n",
       "199999       0  10.8762 -5.7105  12.1183  8.0328  11.5577   0.3488  5.2839   \n",
       "\n",
       "          var_7   var_8  ...  var_190  var_191  var_192  var_193  var_194  \\\n",
       "0       18.6266 -4.9200  ...   4.4354   3.9642   3.1364   1.6910  18.5227   \n",
       "1       16.5338  3.1468  ...   7.6421   7.7214   2.5837  10.9516  15.4305   \n",
       "2       14.6155 -4.9193  ...   2.9057   9.7905   1.6704   1.6858  21.6042   \n",
       "3       14.9250 -5.8609  ...   4.4666   4.7433   0.7178   1.4214  23.0347   \n",
       "4       19.2514  6.2654  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876   \n",
       "...         ...     ...  ...      ...      ...      ...      ...      ...   \n",
       "199995  15.1516 -0.6209  ...   6.1415  13.2305   3.9901   0.9388  18.0249   \n",
       "199996  21.5940 -3.6797  ...   4.9611   4.6549   0.6998   1.8341  22.2717   \n",
       "199997  21.5571  0.1202  ...   4.0651   5.4414   3.1032   4.8793  23.5311   \n",
       "199998  17.0152 -2.1926  ...   2.6840   8.6587   2.7337  11.1178  20.4158   \n",
       "199999  15.2058 -0.4541  ...   8.9842   1.6893   0.1276   0.3766  15.2101   \n",
       "\n",
       "        var_195  var_196  var_197  var_198  var_199  \n",
       "0       -2.3978   7.8784   8.5635  12.7803  -1.0914  \n",
       "1        2.0339   8.1267   8.7889  18.3560   1.9518  \n",
       "2        3.1417  -6.5213   8.2675  14.7222   0.3965  \n",
       "3       -1.2706  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4       -1.5121   3.9267   9.5031  17.9974  -8.8104  \n",
       "...         ...      ...      ...      ...      ...  \n",
       "199995  -1.7939   2.1661   8.5326  16.6660 -17.8661  \n",
       "199996   1.7337  -2.1651   6.7419  15.9054   0.3388  \n",
       "199997  -1.5736   1.2832   8.7155  13.8329   4.1995  \n",
       "199998  -0.0786   6.7980  10.0342  15.5289 -13.9001  \n",
       "199999  -2.4907  -2.2342   8.1857  12.1284   0.1385  \n",
       "\n",
       "[200000 rows x 201 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5806ec0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the data into X and Y\n",
    "X = df1.drop('target', axis = 1)\n",
    "Y = df1['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4caa1872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 200)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape  # Shape of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "704beb88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200000,),\n",
       " 0    179902\n",
       " 1     20098\n",
       " Name: target, dtype: int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape,Y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16bd9296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can notice that their is a more dimensions, Data is imbalaced & Target feature  is imbalanced \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fac121",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7ed49c",
   "metadata": {},
   "source": [
    "EDA cannot be done for this dataset because there are no feature names are provided in the given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d04f396",
   "metadata": {},
   "source": [
    "# Outliers\n",
    "\n",
    " We cannot find outliers as EDA is not done for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4190cf06",
   "metadata": {},
   "source": [
    "# Principal Component Analysis (PCA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e8c19e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -5.60646899, -23.55440926,  -1.899704  , ...,   5.41563294,\n",
       "          1.98110756,   5.4449445 ],\n",
       "       [ 34.87802792,  11.46929107,  -3.75977398, ...,  -2.92756827,\n",
       "         -0.47994981,  -2.75461323],\n",
       "       [ -4.79023946,  -0.33421344,  11.35931802, ...,   1.1990427 ,\n",
       "         -2.04303563,   4.956015  ],\n",
       "       ...,\n",
       "       [ 36.84227048,   7.76008289,  30.23221393, ...,   1.26350447,\n",
       "          4.61521089,   0.41376635],\n",
       "       [ 30.23091675, -24.4235161 ,  25.55355302, ...,   5.882554  ,\n",
       "         -0.32885376,   2.80609371],\n",
       "       [ -5.99488377,   7.69716402,  10.11166579, ...,  -4.22976642,\n",
       "         -1.09201667,   1.02511155]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### As features are more and column names are unknown as process of diemensinality reduction we choosen  PCA\n",
    "pca = PCA(n_components = 0.95, svd_solver = 'full')\n",
    "X_pca = pca.fit_transform(X)\n",
    "X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "170d25cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 111)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e532cbce",
   "metadata": {},
   "source": [
    "# Scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f9769a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardization of Data by MinMaxScaler due imbalanced data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c43d002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -5.60646899, -23.55440926,  -1.899704  , ...,   5.41563294,\n",
       "          1.98110756,   5.4449445 ],\n",
       "       [ 34.87802792,  11.46929107,  -3.75977398, ...,  -2.92756827,\n",
       "         -0.47994981,  -2.75461323],\n",
       "       [ -4.79023946,  -0.33421344,  11.35931802, ...,   1.1990427 ,\n",
       "         -2.04303563,   4.956015  ],\n",
       "       ...,\n",
       "       [ 36.84227048,   7.76008289,  30.23221393, ...,   1.26350447,\n",
       "          4.61521089,   0.41376635],\n",
       "       [ 30.23091675, -24.4235161 ,  25.55355302, ...,   5.882554  ,\n",
       "         -0.32885376,   2.80609371],\n",
       "       [ -5.99488377,   7.69716402,  10.11166579, ...,  -4.22976642,\n",
       "         -1.09201667,   1.02511155]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "527355cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 111)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d12b320f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45343851, 0.25950483, 0.46096636, ..., 0.69513416, 0.58801738,\n",
       "        0.74316446],\n",
       "       [0.71872261, 0.59361521, 0.4426078 , ..., 0.37696545, 0.47557262,\n",
       "        0.35750013],\n",
       "       [0.45878705, 0.48101508, 0.59183054, ..., 0.53433412, 0.40415583,\n",
       "        0.72016778],\n",
       "       ...,\n",
       "       [0.73159376, 0.55823103, 0.77810267, ..., 0.53679238, 0.70836854,\n",
       "        0.50652415],\n",
       "       [0.68827133, 0.25121394, 0.73192512, ..., 0.71294023, 0.48247614,\n",
       "        0.61904672],\n",
       "       [0.45089333, 0.55763081, 0.57951644, ..., 0.32730601, 0.44760752,\n",
       "        0.53527863]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_pca1 = scaler.transform(X_pca)\n",
    "X_pca1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf8fce1",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab824496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balancing the imbalanced target feature\n",
    "smote=SMOTE()\n",
    "X_resampled, Y_resampled = smote.fit_resample(X_pca1,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60b9debd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    179902\n",
       "1    179902\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c960991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(359804, 111)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469c5004",
   "metadata": {},
   "source": [
    "# Models creation and Models evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88446f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_resampled, Y_resampled, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aaa5363",
   "metadata": {},
   "source": [
    "# 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "977c925a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Accuracy: 0.7263779371242982\n",
      "Test_Accuracy: 0.7240184543551167\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Creating a Logistic Regression classifier\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Training the classifier on the training set\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# Predicting the labels for train & test data\n",
    "Y_pred = clf.predict(X_test)\n",
    "Y1_pred = clf.predict(X_train)\n",
    "\n",
    "# Evaluating the accuracy of the train data & test data\n",
    "train_accuracy = accuracy_score(Y_train, Y1_pred)\n",
    "test_accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Train_Accuracy:\", train_accuracy)\n",
    "print(\"Test_Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3a3bd5d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.728001</td>\n",
       "      <td>0.722297</td>\n",
       "      <td>0.725111</td>\n",
       "      <td>0.725149</td>\n",
       "      <td>0.725148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.718587</td>\n",
       "      <td>0.731633</td>\n",
       "      <td>0.725111</td>\n",
       "      <td>0.725110</td>\n",
       "      <td>0.725111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.723263</td>\n",
       "      <td>0.726935</td>\n",
       "      <td>0.725111</td>\n",
       "      <td>0.725099</td>\n",
       "      <td>0.725100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>125904.000000</td>\n",
       "      <td>125958.000000</td>\n",
       "      <td>0.725111</td>\n",
       "      <td>251862.000000</td>\n",
       "      <td>251862.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0              1  accuracy      macro avg  \\\n",
       "precision       0.728001       0.722297  0.725111       0.725149   \n",
       "recall          0.718587       0.731633  0.725111       0.725110   \n",
       "f1-score        0.723263       0.726935  0.725111       0.725099   \n",
       "support    125904.000000  125958.000000  0.725111  251862.000000   \n",
       "\n",
       "            weighted avg  \n",
       "precision       0.725148  \n",
       "recall          0.725111  \n",
       "f1-score        0.725100  \n",
       "support    251862.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the classification report of the train data\n",
    "pd.DataFrame(classification_report(Y_train,Y1_pred,output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55a85865",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.726066</td>\n",
       "      <td>0.720297</td>\n",
       "      <td>0.723148</td>\n",
       "      <td>0.723182</td>\n",
       "      <td>0.723183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.717138</td>\n",
       "      <td>0.729164</td>\n",
       "      <td>0.723148</td>\n",
       "      <td>0.723151</td>\n",
       "      <td>0.723148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.721574</td>\n",
       "      <td>0.724703</td>\n",
       "      <td>0.723148</td>\n",
       "      <td>0.723139</td>\n",
       "      <td>0.723138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>53998.000000</td>\n",
       "      <td>53944.000000</td>\n",
       "      <td>0.723148</td>\n",
       "      <td>107942.000000</td>\n",
       "      <td>107942.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0             1  accuracy      macro avg   weighted avg\n",
       "precision      0.726066      0.720297  0.723148       0.723182       0.723183\n",
       "recall         0.717138      0.729164  0.723148       0.723151       0.723148\n",
       "f1-score       0.721574      0.724703  0.723148       0.723139       0.723138\n",
       "support    53998.000000  53944.000000  0.723148  107942.000000  107942.000000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the classification report of the test data\n",
    "pd.DataFrame(classification_report(Y_test,Y_pred,output_dict=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf04665",
   "metadata": {},
   "source": [
    "# 2. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8686e11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Accuracy: 0.9865481890876749\n",
      "Test_Accuracy: 0.760010005373256\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Creating a DecisionTreeClassifier object\n",
    "clf = DecisionTreeClassifier(max_depth=40)\n",
    "\n",
    "# Training the model to the training data\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# Predicting the labels for train & testdata\n",
    "Y_pred = clf.predict(X_test)\n",
    "Y1_pred = clf.predict(X_train)\n",
    "\n",
    "# Evaluating the accuracy of the train data & test data\n",
    "train_accuracy = accuracy_score(Y_train, Y1_pred)\n",
    "test_accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Train_Accuracy:\", train_accuracy)\n",
    "print(\"Test_Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4f2861b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.999275</td>\n",
       "      <td>0.974460</td>\n",
       "      <td>0.986548</td>\n",
       "      <td>0.986867</td>\n",
       "      <td>0.986864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.973797</td>\n",
       "      <td>0.999293</td>\n",
       "      <td>0.986548</td>\n",
       "      <td>0.986545</td>\n",
       "      <td>0.986548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.986372</td>\n",
       "      <td>0.986720</td>\n",
       "      <td>0.986548</td>\n",
       "      <td>0.986546</td>\n",
       "      <td>0.986546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>125904.000000</td>\n",
       "      <td>125958.000000</td>\n",
       "      <td>0.986548</td>\n",
       "      <td>251862.000000</td>\n",
       "      <td>251862.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0              1  accuracy      macro avg  \\\n",
       "precision       0.999275       0.974460  0.986548       0.986867   \n",
       "recall          0.973797       0.999293  0.986548       0.986545   \n",
       "f1-score        0.986372       0.986720  0.986548       0.986546   \n",
       "support    125904.000000  125958.000000  0.986548  251862.000000   \n",
       "\n",
       "            weighted avg  \n",
       "precision       0.986864  \n",
       "recall          0.986548  \n",
       "f1-score        0.986546  \n",
       "support    251862.000000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the classification report of the train data\n",
    "pd.DataFrame(classification_report(Y_train,Y1_pred,output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f0bfdcd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.793412</td>\n",
       "      <td>0.733390</td>\n",
       "      <td>0.76001</td>\n",
       "      <td>0.763401</td>\n",
       "      <td>0.763416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.703415</td>\n",
       "      <td>0.816662</td>\n",
       "      <td>0.76001</td>\n",
       "      <td>0.760038</td>\n",
       "      <td>0.760010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.745708</td>\n",
       "      <td>0.772789</td>\n",
       "      <td>0.76001</td>\n",
       "      <td>0.759248</td>\n",
       "      <td>0.759242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>53998.000000</td>\n",
       "      <td>53944.000000</td>\n",
       "      <td>0.76001</td>\n",
       "      <td>107942.000000</td>\n",
       "      <td>107942.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0             1  accuracy      macro avg   weighted avg\n",
       "precision      0.793412      0.733390   0.76001       0.763401       0.763416\n",
       "recall         0.703415      0.816662   0.76001       0.760038       0.760010\n",
       "f1-score       0.745708      0.772789   0.76001       0.759248       0.759242\n",
       "support    53998.000000  53944.000000   0.76001  107942.000000  107942.000000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the classification report of the test data\n",
    "pd.DataFrame(classification_report(Y_test,Y_pred,output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02bdb96",
   "metadata": {},
   "source": [
    "# 3. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30b70c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Accuracy: 1.0\n",
      "Test_Accuracy: 0.9460080413555428\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Creating a Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Training the classifier on the training set\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# Predicting the labels for the train & test data\n",
    "Y_pred = clf.predict(X_test)\n",
    "Y1_pred = clf.predict(X_train)\n",
    "\n",
    "\n",
    "# Evaluating the accuracy of the train data & test data\n",
    "train_accuracy = accuracy_score(Y_train, Y1_pred)\n",
    "test_accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Train_Accuracy:\", train_accuracy)\n",
    "print(\"Test_Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22df0139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>125904.0</td>\n",
       "      <td>125958.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>251862.0</td>\n",
       "      <td>251862.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1  accuracy  macro avg  weighted avg\n",
       "precision       1.0       1.0       1.0        1.0           1.0\n",
       "recall          1.0       1.0       1.0        1.0           1.0\n",
       "f1-score        1.0       1.0       1.0        1.0           1.0\n",
       "support    125904.0  125958.0       1.0   251862.0      251862.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the classification report of the train data\n",
    "pd.DataFrame(classification_report(Y_train,Y1_pred,output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e3116c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.927752</td>\n",
       "      <td>0.965915</td>\n",
       "      <td>0.946008</td>\n",
       "      <td>0.946834</td>\n",
       "      <td>0.946824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.967406</td>\n",
       "      <td>0.924588</td>\n",
       "      <td>0.946008</td>\n",
       "      <td>0.945997</td>\n",
       "      <td>0.946008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.947164</td>\n",
       "      <td>0.944800</td>\n",
       "      <td>0.946008</td>\n",
       "      <td>0.945982</td>\n",
       "      <td>0.945983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>53998.000000</td>\n",
       "      <td>53944.000000</td>\n",
       "      <td>0.946008</td>\n",
       "      <td>107942.000000</td>\n",
       "      <td>107942.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0             1  accuracy      macro avg   weighted avg\n",
       "precision      0.927752      0.965915  0.946008       0.946834       0.946824\n",
       "recall         0.967406      0.924588  0.946008       0.945997       0.946008\n",
       "f1-score       0.947164      0.944800  0.946008       0.945982       0.945983\n",
       "support    53998.000000  53944.000000  0.946008  107942.000000  107942.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the classification report of the test data\n",
    "pd.DataFrame(classification_report(Y_test,Y_pred,output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c52621d",
   "metadata": {},
   "source": [
    "# 4. Support Vector Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec567562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Accuracy: 0.725695023465231\n",
      "Test_Accuracy: 0.724213003279539\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Creating an SVM classifier\n",
    "clf = SVC(kernel='linear')\n",
    "\n",
    "# Training the classifier on the training set\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "# Predicting the labels for train & test data\n",
    "Y_pred = clf.predict(X_test)\n",
    "Y1_pred = clf.predict(X_train)\n",
    "\n",
    "\n",
    "# Evaluating the accuracy for the train data & test data\n",
    "train_accuracy = accuracy_score(Y_train, Y1_pred)\n",
    "test_accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Train_Accuracy:\", train_accuracy)\n",
    "print(\"Test_Accuracy:\", test_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0579dac",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.733509</td>\n",
       "      <td>0.718394</td>\n",
       "      <td>0.725695</td>\n",
       "      <td>0.725951</td>\n",
       "      <td>0.725950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.708778</td>\n",
       "      <td>0.742605</td>\n",
       "      <td>0.725695</td>\n",
       "      <td>0.725691</td>\n",
       "      <td>0.725695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.720932</td>\n",
       "      <td>0.730299</td>\n",
       "      <td>0.725695</td>\n",
       "      <td>0.725615</td>\n",
       "      <td>0.725616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>125904.000000</td>\n",
       "      <td>125958.000000</td>\n",
       "      <td>0.725695</td>\n",
       "      <td>251862.000000</td>\n",
       "      <td>251862.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0              1  accuracy      macro avg  \\\n",
       "precision       0.733509       0.718394  0.725695       0.725951   \n",
       "recall          0.708778       0.742605  0.725695       0.725691   \n",
       "f1-score        0.720932       0.730299  0.725695       0.725615   \n",
       "support    125904.000000  125958.000000  0.725695  251862.000000   \n",
       "\n",
       "            weighted avg  \n",
       "precision       0.725950  \n",
       "recall          0.725695  \n",
       "f1-score        0.725616  \n",
       "support    251862.000000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the classification report of the train data\n",
    "pd.DataFrame(classification_report(Y_train,Y1_pred,output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84a86e1c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.732208</td>\n",
       "      <td>0.716735</td>\n",
       "      <td>0.724213</td>\n",
       "      <td>0.724471</td>\n",
       "      <td>0.724475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.707434</td>\n",
       "      <td>0.741009</td>\n",
       "      <td>0.724213</td>\n",
       "      <td>0.724221</td>\n",
       "      <td>0.724213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.719607</td>\n",
       "      <td>0.728670</td>\n",
       "      <td>0.724213</td>\n",
       "      <td>0.724139</td>\n",
       "      <td>0.724136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>53998.000000</td>\n",
       "      <td>53944.000000</td>\n",
       "      <td>0.724213</td>\n",
       "      <td>107942.000000</td>\n",
       "      <td>107942.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0             1  accuracy      macro avg   weighted avg\n",
       "precision      0.732208      0.716735  0.724213       0.724471       0.724475\n",
       "recall         0.707434      0.741009  0.724213       0.724221       0.724213\n",
       "f1-score       0.719607      0.728670  0.724213       0.724139       0.724136\n",
       "support    53998.000000  53944.000000  0.724213  107942.000000  107942.000000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the classification report of the test data\n",
    "pd.DataFrame(classification_report(Y_test,Y_pred,output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea76d2a7",
   "metadata": {},
   "source": [
    "# 5. KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ac12239",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4997498656685998\n",
      "Train_Accuracy: 0.5001072015627606\n",
      "Test_Accuracy: 0.4997498656685998\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Creating a KNeighborsClassifier object with k=5\n",
    "clf = KNeighborsClassifier(n_neighbors=35)\n",
    "\n",
    "\n",
    "# Training the model to the training data\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# Predicting the labels of the train & test data\n",
    "Y_pred = clf.predict(X_test)\n",
    "Y1_pred = clf.predict(X_train)\n",
    "\n",
    "# Calculating the accuracy of the train data & test data\n",
    "train_accuracy = accuracy_score(Y_train, Y1_pred)\n",
    "test_accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Train_Accuracy:\", train_accuracy)\n",
    "print(\"Test_Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fec6f527",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500107</td>\n",
       "      <td>0.500107</td>\n",
       "      <td>0.250054</td>\n",
       "      <td>0.250107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500107</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666762</td>\n",
       "      <td>0.500107</td>\n",
       "      <td>0.333381</td>\n",
       "      <td>0.333452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>125904.0</td>\n",
       "      <td>125958.000000</td>\n",
       "      <td>0.500107</td>\n",
       "      <td>251862.000000</td>\n",
       "      <td>251862.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0              1  accuracy      macro avg   weighted avg\n",
       "precision       0.0       0.500107  0.500107       0.250054       0.250107\n",
       "recall          0.0       1.000000  0.500107       0.500000       0.500107\n",
       "f1-score        0.0       0.666762  0.500107       0.333381       0.333452\n",
       "support    125904.0  125958.000000  0.500107  251862.000000  251862.000000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the classification report of the train data\n",
    "pd.DataFrame(classification_report(Y_train,Y1_pred,output_dict=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f77ac500",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Dell\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499750</td>\n",
       "      <td>0.49975</td>\n",
       "      <td>0.249875</td>\n",
       "      <td>0.249750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.49975</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.499750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666444</td>\n",
       "      <td>0.49975</td>\n",
       "      <td>0.333222</td>\n",
       "      <td>0.333055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>53998.0</td>\n",
       "      <td>53944.000000</td>\n",
       "      <td>0.49975</td>\n",
       "      <td>107942.000000</td>\n",
       "      <td>107942.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1  accuracy      macro avg   weighted avg\n",
       "precision      0.0      0.499750   0.49975       0.249875       0.249750\n",
       "recall         0.0      1.000000   0.49975       0.500000       0.499750\n",
       "f1-score       0.0      0.666444   0.49975       0.333222       0.333055\n",
       "support    53998.0  53944.000000   0.49975  107942.000000  107942.000000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the classification report of the test data\n",
    "pd.DataFrame(classification_report(Y_test,Y_pred,output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2e79b1",
   "metadata": {},
   "source": [
    "# 6. Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "15060656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Accuracy: 0.8338177255798811\n",
      "Test_Accuracy: 0.8355135165181301\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Creating a Naive Bayes classifier\n",
    "clf = GaussianNB()\n",
    "\n",
    "# Training the classifier on the training set\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# Predicting the labels of the train & test data\n",
    "Y_pred = clf.predict(X_test)\n",
    "Y1_pred = clf.predict(X_train)\n",
    "\n",
    "# Evaluating the accuracy of the tarin data & test data\n",
    "train_accuracy = accuracy_score(Y_train, Y1_pred)\n",
    "test_accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Train_Accuracy:\", train_accuracy)\n",
    "print(\"Test_Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ef08911",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.806388</td>\n",
       "      <td>0.866618</td>\n",
       "      <td>0.833818</td>\n",
       "      <td>0.836503</td>\n",
       "      <td>0.836510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.878487</td>\n",
       "      <td>0.789168</td>\n",
       "      <td>0.833818</td>\n",
       "      <td>0.833827</td>\n",
       "      <td>0.833818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.840895</td>\n",
       "      <td>0.826082</td>\n",
       "      <td>0.833818</td>\n",
       "      <td>0.833488</td>\n",
       "      <td>0.833487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>125904.000000</td>\n",
       "      <td>125958.000000</td>\n",
       "      <td>0.833818</td>\n",
       "      <td>251862.000000</td>\n",
       "      <td>251862.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0              1  accuracy      macro avg  \\\n",
       "precision       0.806388       0.866618  0.833818       0.836503   \n",
       "recall          0.878487       0.789168  0.833818       0.833827   \n",
       "f1-score        0.840895       0.826082  0.833818       0.833488   \n",
       "support    125904.000000  125958.000000  0.833818  251862.000000   \n",
       "\n",
       "            weighted avg  \n",
       "precision       0.836510  \n",
       "recall          0.833818  \n",
       "f1-score        0.833487  \n",
       "support    251862.000000  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the classification report of the train data\n",
    "pd.DataFrame(classification_report(Y_train,Y1_pred,output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b70c03c7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.808593</td>\n",
       "      <td>0.867632</td>\n",
       "      <td>0.835514</td>\n",
       "      <td>0.838113</td>\n",
       "      <td>0.838098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.879347</td>\n",
       "      <td>0.791636</td>\n",
       "      <td>0.835514</td>\n",
       "      <td>0.835492</td>\n",
       "      <td>0.835514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.842487</td>\n",
       "      <td>0.827894</td>\n",
       "      <td>0.835514</td>\n",
       "      <td>0.835190</td>\n",
       "      <td>0.835194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>53998.000000</td>\n",
       "      <td>53944.000000</td>\n",
       "      <td>0.835514</td>\n",
       "      <td>107942.000000</td>\n",
       "      <td>107942.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0             1  accuracy      macro avg   weighted avg\n",
       "precision      0.808593      0.867632  0.835514       0.838113       0.838098\n",
       "recall         0.879347      0.791636  0.835514       0.835492       0.835514\n",
       "f1-score       0.842487      0.827894  0.835514       0.835190       0.835194\n",
       "support    53998.000000  53944.000000  0.835514  107942.000000  107942.000000"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the classification report of the test data\n",
    "pd.DataFrame(classification_report(Y_test,Y_pred,output_dict=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4678cbfe",
   "metadata": {},
   "source": [
    "# 7. Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b11bf43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_Accuracy: 0.8413456575426226\n",
      "Test_Accuracy: 0.8228771006651721\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Creating a Neural Network classifier\n",
    "clf = MLPClassifier(hidden_layer_sizes=(100,))\n",
    "\n",
    "# Training the classifier on the training set\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "# Predicting the labels of the train & test data\n",
    "Y_pred = clf.predict(X_test)\n",
    "Y1_pred = clf.predict(X_train)\n",
    "\n",
    "\n",
    "# Evaluating the accuracy of the train data & test data\n",
    "train_accuracy = accuracy_score(Y_train, Y1_pred)\n",
    "test_accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Train_Accuracy:\", train_accuracy)\n",
    "print(\"Test_Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aba1fd5d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.867478</td>\n",
       "      <td>0.818697</td>\n",
       "      <td>0.841346</td>\n",
       "      <td>0.843087</td>\n",
       "      <td>0.843082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.805709</td>\n",
       "      <td>0.876967</td>\n",
       "      <td>0.841346</td>\n",
       "      <td>0.841338</td>\n",
       "      <td>0.841346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.835453</td>\n",
       "      <td>0.846831</td>\n",
       "      <td>0.841346</td>\n",
       "      <td>0.841142</td>\n",
       "      <td>0.841143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>125904.000000</td>\n",
       "      <td>125958.000000</td>\n",
       "      <td>0.841346</td>\n",
       "      <td>251862.000000</td>\n",
       "      <td>251862.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0              1  accuracy      macro avg  \\\n",
       "precision       0.867478       0.818697  0.841346       0.843087   \n",
       "recall          0.805709       0.876967  0.841346       0.841338   \n",
       "f1-score        0.835453       0.846831  0.841346       0.841142   \n",
       "support    125904.000000  125958.000000  0.841346  251862.000000   \n",
       "\n",
       "            weighted avg  \n",
       "precision       0.843082  \n",
       "recall          0.841346  \n",
       "f1-score        0.841143  \n",
       "support    251862.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the classification report of the train data\n",
    "pd.DataFrame(classification_report(Y_train,Y1_pred,output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f885c7cc",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.849875</td>\n",
       "      <td>0.799714</td>\n",
       "      <td>0.822877</td>\n",
       "      <td>0.824794</td>\n",
       "      <td>0.824807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.784511</td>\n",
       "      <td>0.861282</td>\n",
       "      <td>0.822877</td>\n",
       "      <td>0.822896</td>\n",
       "      <td>0.822877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.815886</td>\n",
       "      <td>0.829357</td>\n",
       "      <td>0.822877</td>\n",
       "      <td>0.822621</td>\n",
       "      <td>0.822618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>53998.000000</td>\n",
       "      <td>53944.000000</td>\n",
       "      <td>0.822877</td>\n",
       "      <td>107942.000000</td>\n",
       "      <td>107942.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0             1  accuracy      macro avg   weighted avg\n",
       "precision      0.849875      0.799714  0.822877       0.824794       0.824807\n",
       "recall         0.784511      0.861282  0.822877       0.822896       0.822877\n",
       "f1-score       0.815886      0.829357  0.822877       0.822621       0.822618\n",
       "support    53998.000000  53944.000000  0.822877  107942.000000  107942.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the classification report of the test data\n",
    "pd.DataFrame(classification_report(Y_test,Y_pred,output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d91a4af",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Hyperparameter tuning cannot be done for this dataset as it is not able to fit all the rows and columns since it has huge amount of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebdad03",
   "metadata": {},
   "source": [
    "# Comparison Report of the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "84da98cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "x=PrettyTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2833b18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.field_names = [\"Model\",\"(test)Accuracy\", \"(train)Accuracy\"]\n",
    "x.add_row([\"Logistic Regression\",'72.3 %','72.5%'])\n",
    "x.add_row([\"Decision Trees Classifier\",' 76 %','98 %'])\n",
    "x.add_row([\"Random Forest Classifier\", '94 %','100 %'])\n",
    "x.add_row([\"Support Vector Classifier\",'72.4 %','72.5 %'])\n",
    "x.add_row([\"K-Nearest Neighbor Classifier\", '49 %','50%'])\n",
    "x.add_row([\"Naive Bayes classifier\",'83.5 %','83.3 %'])\n",
    "x.add_row([\"Neural Network classifier\",'82.2%','84.1 %'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a76b62c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+----------------+-----------------+\n",
      "|             Model             | (test)Accuracy | (train)Accuracy |\n",
      "+-------------------------------+----------------+-----------------+\n",
      "|      Logistic Regression      |     72.3 %     |      72.5%      |\n",
      "|   Decision Trees Classifier   |      76 %      |       98 %      |\n",
      "|    Random Forest Classifier   |      94 %      |      100 %      |\n",
      "|   Support Vector Classifier   |     72.4 %     |      72.5 %     |\n",
      "| K-Nearest Neighbor Classifier |      49 %      |       50%       |\n",
      "|     Naive Bayes classifier    |     83.5 %     |      83.3 %     |\n",
      "|   Neural Network classifier   |     82.2%      |      84.1 %     |\n",
      "+-------------------------------+----------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ad17d1",
   "metadata": {},
   "source": [
    "#  From above we came to conclude that Random Forest Classifier is the best model for this dataset \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4dc2d97c",
   "metadata": {},
   "source": [
    "  More evaluation on Randomforest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faf38ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Creating the model\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# Creating the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Performing Grid Search with 5-fold cross validation\n",
    "grid_search = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "# Fiting the grid search to the data\n",
    "grid_search.fit(X_train, Y_train)\n",
    "\n",
    "# Printing the best parameters and best score\n",
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "print(\"Best Score: \", grid_search.best_score_)\n",
    "\n",
    "# Evaluating the model on the test data\n",
    "Y_pred = grid_search.predict(X_test)\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(\"Accuracy on test data: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b1f391",
   "metadata": {},
   "source": [
    "# MODEL EVALUATING ON RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69461d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9659152529243163\n",
      "Recall: 0.9245884621088536\n",
      "F1 Score: 0.9448001515438531\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "#clf = RandomForestClassifier(n_estimators=100)\n",
    "#clf.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "# Making predictions on the test set\n",
    "#Y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculating precision, recall, and F1 score\n",
    "precision = precision_score(Y_test, Y_pred)\n",
    "recall = recall_score(Y_test, Y_pred)\n",
    "f1 = f1_score(Y_test, Y_pred)\n",
    "\n",
    "# Calculating confusion matrix\n",
    "#cm = confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "# Printing  results\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "#print(\"Confusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f79e718c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.9859195935335915\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "# Predicting probabilities on test data\n",
    "Y_prob = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Computing ROC curve and ROC AUC score\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, Y_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Ploting ROC curve\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Printing AUC score\n",
    "print(\"AUC Score:\", roc_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491e28e3",
   "metadata": {},
   "source": [
    "# Conclusion Report\n",
    "- Based on the given values, the performance of several classification algorithms is analyzed. The models are evaluated on training accuracy and testing accuracy.\n",
    "\n",
    "- Logistic Regression: The training and testing accuracy of logistic regression is 72.5% and 72.3% respectively. The model seems to be performing decently well.\n",
    "\n",
    "- Decision Tree Classifier: The training accuracy of the decision tree classifier is very high (98%), but the testing accuracy is 76%. This indicates that the model may be overfitting on the training data.\n",
    "\n",
    "- Random Forest Classifier: The random forest classifier has a training accuracy of 100% and a testing accuracy of 94%. This suggests that the model is likely to perform well on new data.\n",
    "\n",
    "- Support Vector Classifier: The training and testing accuracy of support vector classifier is 72.5% and 72.4% respectively. The model seems to be performing decently well.\n",
    "\n",
    "- KNN Classifier: The KNN classifier has a training accuracy of 50% and a testing accuracy of 49%. This indicates that the model is not performing well and may require further optimization.\n",
    "\n",
    "- Naive Bayes Classifier: The Naive Bayes classifier has a training accuracy of 83.3% and a testing accuracy of 83.5%. This indicates that the model is performing well and is able to generalize to new data.\n",
    "\n",
    "- Neural Network Classifier: The neural network classifier has a training accuracy of 84.1% and a testing accuracy of 82.2%. Although the training accuracy is slightly better than the testing accuracy, the model seems to be performing well.\n",
    "\n",
    "- In conclusion, the random forest classifier, Naive Bayes classifier, and neural network classifier seem to be the best performing models, as they have high testing accuracies and are likely to generalize well to new data. The decision tree classifier, KNN classifier, logistic regression, and support vector classifier may require further optimization to improve their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5b5c69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
